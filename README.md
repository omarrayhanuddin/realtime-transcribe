# Real-Time Microphone Transcription
**FastAPI (backend) + Tortoise ORM + Next.js (App Router v16 frontend) + Vosk (CPU-only)**

A complete real-time microphone transcription system built with:
- **FastAPI** backend (WebSocket + REST)
- **Tortoise ORM** for database
- **Material UI** dark-themed **Next.js App Router (v16)** frontend
- **Vosk** CPU-only speech recognition
- **uv** Python package manager
- **Docker** & docker-compose

---

## ğŸš€ Features
- ğŸ¤ **Browser microphone capture** with real-time streaming
- ğŸ”Œ **WebSocket audio â†’ FastAPI â†’ Vosk** pipeline
- âœï¸ **Live partial transcription** + final text
- ğŸ—ƒ **Session storage** (Tortoise ORM)
- ğŸ§¾ Session metadata: timestamp, duration, word count, transcript, model
- ğŸ’½ SQLite by default (Postgres-ready)
- ğŸ§ª Minimal backend tests
- ğŸ³ Dockerized

---

# ğŸ— Architecture Overview
```
Browser Mic â†’ PCM Audio â†’ WebSocket â†’ FastAPI
            â†˜ partial + final transcripts â†™
         Tortoise ORM â†’ SQLite â†’ /sessions API
Frontend (Next.js) â† REST + WebSocket updates
```

---

# ğŸ“ Repo Structure
```
realtime-transcription/
backend/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”œâ”€â”€ sessions.py         # REST endpoints
â”‚   â”‚   â”œâ”€â”€ websocket.py        # WebSocket streaming endpoint
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py               # Environment + settings
â”‚   â”œâ”€â”€ db.py                   # Tortoise ORM init + connect
â”‚   â”œâ”€â”€ helpers.py              # Vosk helpers
â”‚   â”œâ”€â”€ main.py                 # FastAPI app factory + router include
â”‚   â”œâ”€â”€ models.py               # Tortoise ORM models
â”‚   â”œâ”€â”€ schemas.py              # Pydantic schemas
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ speech_to_text_models/      # Vosk CPU model folder
â”‚   â””â”€â”€ vosk-model-small-en-us-0.15/
â”‚
â”œâ”€â”€ migrations/                 # Tortoise ORM migrations
â”œâ”€â”€ tests/                      # pytest tests
â”‚
â”œâ”€â”€ .env                        # Backend env variables
â”œâ”€â”€ .env.example
â”œâ”€â”€ pyproject.toml              # uv project
â”œâ”€â”€ uv.lock
â”œâ”€â”€ Dockerfile
â””â”€â”€ .dockerignore
frontend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ page.tsx
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ MicRecorder.tsx
â”‚   â”‚   â”œâ”€â”€ TranscriptDisplay.tsx
â”‚   â”‚   â””â”€â”€ SessionList.tsx
â”‚   â””â”€â”€ styles/
â”‚
â”œâ”€â”€ public/
â”œâ”€â”€ package.json
â””â”€â”€ .env

```

---

# ğŸ“¦ Backend Setup (FastAPI + Tortoise ORM + uv)

## 1ï¸âƒ£ Install **uv**
* #### Official installation page â†’ https://docs.astral.sh/uv/getting-started/installation/

### Direct commands:

####  macOS / Linux
```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

####  Windows (PowerShell)
```powershell
powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"
```

---

## 2ï¸âƒ£ Install backend dependencies
### Go to backend folder:
```bash
cd backend
```



### Install dependencies:
```bash
uv sync
```

### Run backend:
```bash
uv run uvicorn app.main:app --reload --port 8000
```

### Run tests:
```bash
uv run pytest -q
```

---


## ğŸ™ï¸ Vosk Model (Bundled by Default â€” No Download Required)
This project **already includes** the **Vosk Small English Model (`vosk-model-small-en-us-0.15`)** inside the repository so users **do not need to download anything manually**.


The model is stored at:
```
backend/speech_to_text_models/vosk-model-small-en-us-0.15/
```


### Why bundle the model?
- âœ” No external download steps
- âœ” Works **offline by default**
- âœ” Faster onboarding for users and assessors
- âœ” Docker builds are selfâ€‘contained


The backend automatically loads the model using:
```
VOSK_MODEL_PATH=speech_to_text_models/vosk-model-small-en-us-0.15
```


If you'd like to use a different Vosk model, simply replace the folder and update the env variable.


---

## 4ï¸âƒ£ Environment Variables (`backend/.env`)
```
DATABASE_URL=sqlite://transcriptions.db
VOSK_MODEL_PATH=speech_to_text_models/vosk-model-small-en-us-0.15
SAMPLE_RATE=16000
```

---


---

# ğŸŒ Frontend Setup (Next.js 16 + Material UI)

```bash
cd frontend
npm install
```

Create environment file:
```
NEXT_PUBLIC_BACKEND_WS_URL=ws://localhost:8000/ws/transcribe
NEXT_PUBLIC_BACKEND_API_URL=http://localhost:8000
```

Start frontend:
```bash
npm run dev
```

Open browser:  
http://localhost:3000

---

# ğŸ³ Docker Compose
From root:
```bash
docker-compose up --build
```
Backend â†’ http://localhost:8000  
Frontend â†’ http://localhost:3000

---

# ğŸ“¡ API Documentation

## ğŸ”Š WebSocket â€” `/ws/transcribe`
Send **binary PCM (16-bit, 16 kHz mono)**.

### Partial message
```json
{ "type": "partial", "text": "hello wo" }
```

### Final message
```json
{
  "type": "final",
  "text": "hello world",
  "word_count": 2,
  "duration_seconds": 1.25,
  "session_id": 3
}
```

---

## ğŸ“ REST Endpoints
### `GET /sessions`
List sessions.
```bash
curl http://localhost:8000/sessions
```

### `GET /sessions/{id}`
Get session by ID.
```bash
curl http://localhost:8000/sessions/1
```

---

# ğŸ—„ Database Schema (Tortoise ORM)
`models.py`:
```python
class TranscriptionSession(Model):
    id = IntField(pk=True)
    created_at = DatetimeField(auto_now_add=True)
    duration_seconds = FloatField(default=0.0)
    word_count = IntField(default=0)
    transcript_text = TextField()
    model_name = CharField(max_length=255, default="vosk-small-en-us-0.15")
    language = CharField(max_length=10, default="en")
```

SQLite auto-generates the table on startup if `generate_schemas=True`.

---

# ğŸ§ª Tests
Run with uv:
```bash
cd backend
uv run pytest -q
```

Includes sample tests:
- Empty sessions list
- Insert + fetch session

---

# ğŸ’¡ Design Choices
- Tortoise ORM for async-first DB layer (matching FastAPI async model)
- Vosk for local CPU-only inference
- Next.js App Router + MUI for modern UX
- WebSocket for real-time streaming
- uv for reproducible and fast Python env management

---

# âš ï¸ Limitations
- PCM audio only
- No authentication
- Accuracy limited by Vosk small model
- Browser must run on HTTPS for mic on production

---

# ğŸš€ Future Enhancements
- Whisper.cpp backend option
- User accounts + session filtering
- Pagination for `/sessions`
- Mobile-friendly MUI gestures
- Real-time UI charts (volume, WPM)

---

