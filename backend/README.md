# ğŸ¤ Real-Time Microphone Transcription â€” Backend
**FastAPI + WebSockets + Tortoise ORM + Vosk (CPU-only) + uv**

This backend powers a real-time speech-to-text system using Vosk for offline transcription and FastAPI WebSockets for streaming audio.

---

## ğŸš€ Features
- Real-time audio streaming using **WebSockets**
- Offline transcription using **Vosk Small Model** (bundled by default)
- **Tortoise ORM** async database layer
- **SQLite** by default, Postgres-ready
- Session storage: transcript, duration, word count, timestamps
- Minimal backend tests
- Dockerized

---

## ğŸ“ Project Structure
```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”œâ”€â”€ sessions.py
â”‚   â”‚   â”œâ”€â”€ websocket.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ db.py
â”‚   â”œâ”€â”€ helpers.py
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ models.py
â”‚   â”œâ”€â”€ schemas.py
â”‚
â”œâ”€â”€ speech_to_text_models/
â”‚   â””â”€â”€ vosk-model-small-en-us-0.15/
â”‚
â”œâ”€â”€ migrations/
â”œâ”€â”€ tests/
â”‚
â”œâ”€â”€ .env
â”œâ”€â”€ .env.example
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ uv.lock
â”œâ”€â”€ Dockerfile
â””â”€â”€ .dockerignore
```

---

## ğŸ—£ï¸ Vosk Model Included (No Download Required)
The backend ships with the **Vosk Small English Model**:

```
backend/speech_to_text_models/vosk-model-small-en-us-0.15/
```

Environment variable:
```
VOSK_MODEL_PATH=speech_to_text_models/vosk-model-small-en-us-0.15
```

---

## ğŸ›  Installation (uv + FastAPI)

### 1ï¸âƒ£ Install uv  
Mac/Linux:
```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

Windows:
```powershell
powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"
```

### 2ï¸âƒ£ Install dependencies
```bash
cd backend
uv sync
```

### 3ï¸âƒ£ Run server
```bash
uv run uvicorn app.main:app --reload --port 8000
```

### 4ï¸âƒ£ Run tests
```bash
uv run pytest -q
```

---

## âš™ï¸ Environment Variables
Create `.env` inside `backend/`:

```
DATABASE_URL=sqlite://transcriptions.db
VOSK_MODEL_PATH=speech_to_text_models/vosk-model-small-en-us-0.15
SAMPLE_RATE=16000
```

---

## ğŸ”Œ WebSocket API â€” `/ws/transcribe`
Send binary PCM audio (16-bit, 16 kHz mono).

**Partial message:**
```json
{ "type": "partial", "text": "hello wo" }
```

**Final message:**
```json
{
  "type": "final",
  "text": "hello world",
  "word_count": 2,
  "duration_seconds": 1.25,
  "session_id": 3
}
```

---

## ğŸ“¡ REST Endpoints
### List sessions
```bash
curl http://localhost:8000/sessions
```

### Get session by ID
```bash
curl http://localhost:8000/sessions/1
```

---

## ğŸ—„ Database Schema (Tortoise ORM)
```python
class TranscriptionSession(Model):
    id = IntField(pk=True)
    created_at = DatetimeField(auto_now_add=True)
    duration_seconds = FloatField(default=0.0)
    word_count = IntField(default=0)
    transcript_text = TextField()
    model_name = CharField(max_length=255, default="vosk-small-en-us-0.15")
    language = CharField(max_length=10, default="en")
```

---

## ğŸ³ Docker
From project root:
```bash
docker-compose up --build
```

Backend â†’ http://localhost:8000  

---

## âš ï¸ Limitations
- PCM audio only  
- No authentication  
- Vosk small model has limited accuracy  
- HTTPS required for mic access in production  

---

## ğŸš€ Future Work
- Whisper.cpp backend  
- User authentication  
- Session pagination  
- Real-time audio level visualization  

---